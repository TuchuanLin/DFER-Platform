#!/usr/bin/env python3
"""
æ£€æŸ¥å’Œä¿®å¤æ¨¡å‹é—®é¢˜çš„ä¸“ç”¨å·¥å…·
"""

import sys
import os
import torch
import numpy as np
from pathlib import Path
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from fer_platform.models.improved_m3d_wrapper import ImprovedM3DInferenceWrapper
from fer_platform.config import config
from core_model.models.M3D import M3DFEL

def check_model_weights():
    """æ£€æŸ¥æ¨¡å‹æƒé‡æ˜¯å¦æ­£å¸¸åŠ è½½"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹æƒé‡çŠ¶æ€...")
    print("=" * 50)
    
    model_path = config.get_model_path()
    print(f"æ¨¡å‹æ–‡ä»¶è·¯å¾„: {model_path}")
    
    if not model_path or not Path(model_path).exists():
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        checkpoint = torch.load(model_path, map_location='cpu')
        print(f"âœ… æ¨¡å‹æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # åˆ†æcheckpointç»“æ„
        if isinstance(checkpoint, dict):
            print(f"Checkpoint é”®: {list(checkpoint.keys())}")
            
            # æŸ¥æ‰¾state_dict
            state_dict = None
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
                print("ä½¿ç”¨ 'model_state_dict'")
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
                print("ä½¿ç”¨ 'state_dict'")
            elif 'model' in checkpoint:
                state_dict = checkpoint['model']
                print("ä½¿ç”¨ 'model'")
            else:
                state_dict = checkpoint
                print("ç›´æ¥ä½¿ç”¨ checkpoint ä½œä¸º state_dict")
                
            if state_dict:
                print(f"State dict ä¸­çš„å±‚æ•°: {len(state_dict)}")
                print("å‰10ä¸ªå‚æ•°å±‚:")
                for i, (name, param) in enumerate(list(state_dict.items())[:10]):
                    print(f"  {i+1}. {name}: {param.shape}")
                    
                # æ£€æŸ¥å‚æ•°æ˜¯å¦ä¸ºé›¶æˆ–å¼‚å¸¸
                zero_params = 0
                total_params = 0
                for name, param in state_dict.items():
                    total_params += 1
                    if torch.all(param == 0):
                        zero_params += 1
                        
                print(f"å‚æ•°ç»Ÿè®¡: {total_params} æ€»å‚æ•°, {zero_params} é›¶å‚æ•°")
                if zero_params > total_params * 0.1:  # å¦‚æœè¶…è¿‡10%æ˜¯é›¶å‚æ•°
                    print("âš ï¸  è­¦å‘Š: å‘ç°å¼‚å¸¸å¤šçš„é›¶å‚æ•°")
                    
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ¨¡å‹æƒé‡æ—¶å‡ºé”™: {e}")
        return False

def test_model_predictions():
    """æµ‹è¯•æ¨¡å‹çš„åŸºæœ¬é¢„æµ‹èƒ½åŠ›"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹é¢„æµ‹èƒ½åŠ›...")
    print("=" * 50)
    
    try:
        # åˆ›å»ºä¸åŒå¼ºåº¦çš„åå·®æ ¡æ­£ç‰ˆæœ¬
        configs = [
            {'name': 'æ— æ ¡æ­£', 'enable_bias_correction': False},
            {'name': 'æ¿€è¿›æ ¡æ­£', 'enable_bias_correction': True}
        ]
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_frame = np.random.randint(0, 255, (112, 112, 3), dtype=np.uint8)
        test_frames = [test_frame for _ in range(16)]
        
        for config_test in configs:
            print(f"\nğŸ“Š é…ç½®: {config_test['name']}")
            
            wrapper = ImprovedM3DInferenceWrapper(
                enable_bias_correction=config_test['enable_bias_correction'],
                enable_confidence_filtering=True
            )
            
            # è¿›è¡Œå¤šæ¬¡é¢„æµ‹ï¼Œæ£€æŸ¥ä¸€è‡´æ€§
            predictions = []
            for i in range(5):
                result = wrapper.predict(test_frames)
                predictions.append(result['predicted_label'])
                
            # åˆ†æé¢„æµ‹ä¸€è‡´æ€§
            unique_predictions = set(predictions)
            print(f"  5æ¬¡é¢„æµ‹ç»“æœ: {predictions}")
            print(f"  é¢„æµ‹ä¸€è‡´æ€§: {len(unique_predictions) == 1}")
            
            # æ˜¾ç¤ºæœ€åä¸€æ¬¡çš„è¯¦ç»†ç»“æœ
            result = wrapper.predict(test_frames)
            probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)
            print(f"  æœ€ç»ˆé¢„æµ‹: {result['predicted_label']} (ç½®ä¿¡åº¦: {result['confidence']:.4f})")
            print(f"  æ¦‚ç‡åˆ†å¸ƒ:")
            for emotion, prob in probs:
                print(f"    {emotion}: {prob:.4f}")
                
    except Exception as e:
        print(f"âŒ æµ‹è¯•é¢„æµ‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def apply_extreme_bias_correction():
    """åº”ç”¨æç«¯çš„åå·®æ ¡æ­£æ¥è§£å†³ä¸­æ€§è¿‡åº¦é¢„æµ‹"""
    print("\nğŸ¯ åº”ç”¨æç«¯åå·®æ ¡æ­£...")
    print("=" * 50)
    
    try:
        wrapper = ImprovedM3DInferenceWrapper()
        
        # è®¾ç½®æç«¯çš„åå·®æ ¡æ­£æƒé‡
        extreme_weights = {
            0: 3.0,   # æ„¤æ€’ - æå¤§æé«˜
            1: 2.5,   # åŒæ¶ - æå¤§æé«˜
            2: 3.5,   # ææƒ§ - æå¤§æé«˜
            3: 4.0,   # å¼€å¿ƒ - æœ€å¤§æé«˜
            4: 0.1,   # ä¸­æ€§ - æå¤§é™ä½
            5: 3.0,   # æ‚²ä¼¤ - æå¤§æé«˜
            6: 3.5    # æƒŠè®¶ - æå¤§æé«˜
        }
        
        wrapper.configure_parameters(
            bias_correction_weights=extreme_weights,
            temperature=0.5,  # æ›´ä½çš„æ¸©åº¦
            confidence_threshold=0.1
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_frame = np.random.randint(0, 255, (112, 112, 3), dtype=np.uint8)
        test_frames = [test_frame for _ in range(16)]
        
        print("ä½¿ç”¨æç«¯åå·®æ ¡æ­£è¿›è¡Œé¢„æµ‹...")
        result = wrapper.predict(test_frames)
        
        print(f"é¢„æµ‹ç»“æœ: {result['predicted_label']}")
        print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
        
        probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)
        print("æ¦‚ç‡åˆ†å¸ƒ:")
        for emotion, prob in probs:
            symbol = "ğŸ”¥" if emotion != "ä¸­æ€§" else "â„ï¸"
            print(f"  {symbol} {emotion}: {prob:.4f}")
            
        if result['predicted_label'] != "ä¸­æ€§":
            print("âœ… æˆåŠŸé¿å…ä¸­æ€§è¿‡åº¦é¢„æµ‹ï¼")
        else:
            print("âš ï¸  ä»ç„¶é¢„æµ‹ä¸ºä¸­æ€§ï¼Œå¯èƒ½éœ€è¦æ›´æç«¯çš„è°ƒæ•´")
            
    except Exception as e:
        print(f"âŒ åº”ç”¨æç«¯åå·®æ ¡æ­£æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def diagnose_model_architecture():
    """è¯Šæ–­æ¨¡å‹æ¶æ„é—®é¢˜"""
    print("\nğŸ—ï¸  è¯Šæ–­æ¨¡å‹æ¶æ„...")
    print("=" * 50)
    
    try:
        # ç›´æ¥åˆ›å»ºå’Œæ£€æŸ¥M3Dæ¨¡å‹
        class Args:
            def __init__(self):
                self.num_classes = 7
                self.num_frames = 16
                self.instance_length = 4
                self.gpu_ids = []
        
        args = Args()
        model = M3DFEL(args)
        
        print(f"æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad)}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(1, 16, 3, 112, 112)
        print(f"æµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        model.eval()
        with torch.no_grad():
            output, features = model(test_input)
            print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"è¾“å‡ºæ•°å€¼èŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦å¼‚å¸¸
            if torch.isnan(output).any():
                print("âš ï¸  è­¦å‘Š: è¾“å‡ºåŒ…å« NaN")
            if torch.isinf(output).any():
                print("âš ï¸  è­¦å‘Š: è¾“å‡ºåŒ…å« Inf")
                
            # æŸ¥çœ‹åŸå§‹æ¦‚ç‡åˆ†å¸ƒ
            probs = torch.softmax(output, dim=-1)
            print("åŸå§‹æ¦‚ç‡åˆ†å¸ƒ (softmax):")
            emotion_labels = ["æ„¤æ€’", "åŒæ¶", "ææƒ§", "å¼€å¿ƒ", "ä¸­æ€§", "æ‚²ä¼¤", "æƒŠè®¶"]
            for i, (emotion, prob) in enumerate(zip(emotion_labels, probs[0])):
                print(f"  {emotion}: {prob.item():.4f}")
                
        return True
        
    except Exception as e:
        print(f"âŒ è¯Šæ–­æ¨¡å‹æ¶æ„æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ¨¡å‹è¯Šæ–­å’Œä¿®å¤å·¥å…·")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ¨¡å‹æƒé‡
    weights_ok = check_model_weights()
    
    # 2. è¯Šæ–­æ¨¡å‹æ¶æ„
    arch_ok = diagnose_model_architecture()
    
    # 3. æµ‹è¯•é¢„æµ‹èƒ½åŠ›
    test_model_predictions()
    
    # 4. åº”ç”¨æç«¯åå·®æ ¡æ­£
    apply_extreme_bias_correction()
    
    print("\n" + "=" * 60)
    print("ğŸ è¯Šæ–­å®Œæˆ")
    print("=" * 60)
    
    if weights_ok and arch_ok:
        print("âœ… æ¨¡å‹æ–‡ä»¶å’Œæ¶æ„æ­£å¸¸")
        print("ğŸ’¡ å»ºè®®: é—®é¢˜å¯èƒ½åœ¨äºé¢„è®­ç»ƒæ¨¡å‹æœ¬èº«åå‘ä¸­æ€§é¢„æµ‹")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨æ›´æ¿€è¿›çš„åå·®æ ¡æ­£æˆ–å¯»æ‰¾æ›´å¥½çš„é¢„è®­ç»ƒæ¨¡å‹")
    else:
        print("âŒ å‘ç°æ¨¡å‹é—®é¢˜ï¼Œéœ€è¦æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æˆ–æ¶æ„")

if __name__ == "__main__":
    main() 