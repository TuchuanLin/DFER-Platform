#!/usr/bin/env python3
"""
æ”¹è¿›çš„M3Dæ¨¡å‹æ¨ç†åŒ…è£…å™¨
è§£å†³æ¨¡å‹åå‘é¢„æµ‹æ„¤æ€’å’Œææƒ§çš„é—®é¢˜
"""

import torch
import torch.nn.functional as F
import numpy as np
import cv2
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

from core_model.models.M3D import M3DFEL
from fer_platform.config import config

class MICACLInferenceWrapper:
    """MICACLæ¨¡å‹æ¨ç†åŒ…è£…å™¨ï¼ŒåŸºäºMulti-Instance Contrastive Active Learning"""
    
    # è¡¨æƒ…ç±»åˆ«æ˜ å°„
    EMOTION_LABELS = {
        0: "æ„¤æ€’",
        1: "åŒæ¶", 
        2: "ææƒ§",
        3: "å¼€å¿ƒ",
        4: "ä¸­æ€§",
        5: "æ‚²ä¼¤",
        6: "æƒŠè®¶"
    }
    
    # ä¿ç•™åŸå§‹é¢„è®­ç»ƒæƒé‡è¾“å‡ºï¼Œä¸åº”ç”¨ä»»ä½•åå·®æ ¡æ­£
    BIAS_CORRECTION_WEIGHTS = {
        0: 1.0,    # æ„¤æ€’ - åŸå§‹æƒé‡
        1: 1.0,    # åŒæ¶ - åŸå§‹æƒé‡
        2: 1.0,    # ææƒ§ - åŸå§‹æƒé‡
        3: 1.0,    # å¼€å¿ƒ - åŸå§‹æƒé‡
        4: 1.0,    # ä¸­æ€§ - åŸå§‹æƒé‡
        5: 1.0,    # æ‚²ä¼¤ - åŸå§‹æƒé‡
        6: 1.0     # æƒŠè®¶ - åŸå§‹æƒé‡
    }
    
    # æ¸©åº¦å‚æ•° - ä½¿ç”¨1.0ä¿æŒåŸå§‹è¾“å‡º
    TEMPERATURE = 1.0  # ä¿æŒåŸå§‹è¾“å‡ºåˆ†å¸ƒ
    
    def __init__(self, model_path: str = None, device: str = "auto", 
                 enable_bias_correction: bool = False,  # é»˜è®¤ç¦ç”¨åå·®æ ¡æ­£
                 enable_confidence_filtering: bool = False,  # é»˜è®¤ç¦ç”¨ç½®ä¿¡åº¦è¿‡æ»¤
                 confidence_threshold: float = 0.0):  # é™ä½é˜ˆå€¼
        """
        åˆå§‹åŒ–æ”¹è¿›çš„M3Dæ¨ç†åŒ…è£…å™¨
        """
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # åå·®æ ¡æ­£é…ç½®
        self.enable_bias_correction = enable_bias_correction
        self.enable_confidence_filtering = enable_confidence_filtering
        self.confidence_threshold = confidence_threshold
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šï¼‰
        if model_path is None:
            model_path = config.get_model_path()
        
        # è®¾ç½®è®¾å¤‡
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
            
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        self.model_args = self._get_default_args()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = M3DFEL(self.model_args)
        self.model.to(self.device)
        self.model.eval()
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        model_info = config.get_model_info()
        if model_path and Path(model_path).exists():
            self.load_model(model_path)
            self.logger.info("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        else:
            self.logger.info("ğŸ’¡ æç¤º: å½“å‰ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡è¿è¡Œï¼Œå¦‚éœ€æ›´å¥½çš„è¯†åˆ«æ•ˆæœï¼Œè¯·æ·»åŠ é¢„è®­ç»ƒæ¨¡å‹")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.prediction_history = []
        self.emotion_stats = {emotion: 0 for emotion in self.EMOTION_LABELS.values()}
        
    def _get_default_args(self):
        """è·å–é»˜è®¤æ¨¡å‹å‚æ•°"""
        class Args:
            def __init__(self):
                self.num_classes = 7
                self.num_frames = 16
                self.instance_length = 4
                self.gpu_ids = []
                
        return Args()
    
    def load_model(self, model_path: str):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # å¤„ç†ä¸åŒæ ¼å¼çš„checkpoint
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # åŠ è½½çŠ¶æ€å­—å…¸
            self.model.load_state_dict(state_dict, strict=False)
            self.logger.info(f"é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å®Œæˆ: {model_path}")
            
        except Exception as e:
            self.logger.warning(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¤±è´¥: {e}")
    
    def preprocess_frames(self, frames: List[np.ndarray]) -> torch.Tensor:
        """é¢„å¤„ç†è§†é¢‘å¸§"""
        try:
            processed_frames = []
            
            for frame in frames:
                # ç¡®ä¿æ˜¯3é€šé“RGB
                if len(frame.shape) == 2:
                    frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
                elif frame.shape[2] == 4:
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)
                elif frame.shape[2] == 1:
                    frame = np.repeat(frame, 3, axis=2)
                
                # è°ƒæ•´å¤§å°
                frame = cv2.resize(frame, (112, 112))
                
                # å½’ä¸€åŒ–åˆ°[0,1]
                frame = frame.astype(np.float32) / 255.0
                
                # æ ‡å‡†åŒ–
                mean = np.array([0.485, 0.456, 0.406])
                std = np.array([0.229, 0.224, 0.225])
                frame = (frame - mean) / std
                
                # è½¬æ¢ä¸ºCHWæ ¼å¼
                frame = np.transpose(frame, (2, 0, 1))
                processed_frames.append(frame)
            
            # ç¡®ä¿æœ‰16å¸§
            while len(processed_frames) < 16:
                processed_frames.append(processed_frames[-1])
            processed_frames = processed_frames[:16]
            
            # è½¬æ¢ä¸ºtensor
            tensor = torch.tensor(np.array(processed_frames), dtype=torch.float32)
            tensor = tensor.unsqueeze(0).to(self.device)  # [1, 16, 3, 112, 112]
            
            # ç¡®ä¿å†…å­˜å¸ƒå±€è¿ç»­
            tensor = tensor.contiguous()
            
            return tensor
            
        except Exception as e:
            self.logger.error(f"é¢„å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤tensor
            default_tensor = torch.zeros(1, 16, 3, 112, 112, device=self.device)
            return default_tensor.contiguous()
    
    def apply_bias_correction(self, logits: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨åå·®æ ¡æ­£"""
        if not self.enable_bias_correction:
            return logits
        
        # å°†æ ¡æ­£æƒé‡è½¬æ¢ä¸ºtensor
        correction_weights = torch.tensor(
            [self.BIAS_CORRECTION_WEIGHTS[i] for i in range(len(self.BIAS_CORRECTION_WEIGHTS))],
            device=logits.device, dtype=logits.dtype
        )
        
        # åº”ç”¨æ ¡æ­£æƒé‡
        corrected_logits = logits * correction_weights.unsqueeze(0)
        
        return corrected_logits
    
    def apply_temperature_scaling(self, logits: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨æ¸©åº¦ç¼©æ”¾æ¥è½¯åŒ–åˆ†å¸ƒ"""
        return logits / self.TEMPERATURE
    
    @torch.no_grad()
    def predict(self, frames: List[np.ndarray]) -> Dict[str, Any]:
        """
        æ”¹è¿›çš„é¢„æµ‹æ–¹æ³•ï¼ŒåŒ…å«åå·®æ ¡æ­£
        """
        try:
            # é¢„å¤„ç†
            input_tensor = self.preprocess_frames(frames)
            
            # æ¨ç†
            output, features = self.model(input_tensor)
            
            # ç¡®ä¿è¾“å‡ºç»´åº¦æ­£ç¡® - ä½¿ç”¨reshapeè€Œéviewé¿å…strideé—®é¢˜
            if output.dim() > 2:
                output = output.reshape(output.size(0), -1)
                if output.size(1) != self.model_args.num_classes:
                    output = output[:, -self.model_args.num_classes:]
            elif output.dim() == 1:
                output = output.unsqueeze(0)
            
            if output.size(1) != self.model_args.num_classes:
                self.logger.warning(f"è¾“å‡ºç»´åº¦å¼‚å¸¸: {output.shape}ï¼Œé¢„æœŸ: [1, {self.model_args.num_classes}]")
                # åˆ›å»ºæ­£ç¡®ç»´åº¦çš„è¾“å‡ºï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„æ­£å¸¸åˆ†å¸ƒè€Œä¸æ˜¯éšæœº
                output = torch.zeros(1, self.model_args.num_classes, device=self.device, dtype=torch.float32)
                # åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„å…¸å‹è¾“å‡ºåˆ†å¸ƒåˆå§‹åŒ–
                if config.has_pretrained_model():
                    # ä½¿ç”¨æ¥è¿‘çœŸå®æ¨¡å‹è¾“å‡ºçš„åˆ†å¸ƒ
                    output[0] = torch.tensor([-1.2, -0.8, -1.5, 0.5, 0.2, -0.3, -0.7], 
                                           device=self.device, dtype=torch.float32)
                else:
                    # éšæœºåˆå§‹åŒ–ï¼ˆä»…åœ¨æ— é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼‰
                    output[0] = torch.randn(self.model_args.num_classes, device=self.device)
            
            # ä¿å­˜åŸå§‹è¾“å‡ºç”¨äºæ¯”è¾ƒ
            original_output = output.clone()
            original_probs = F.softmax(original_output, dim=-1)
            original_pred = torch.argmax(original_probs, dim=-1).item()
            original_confidence = original_probs[0][original_pred].item()
            
            # åº”ç”¨æ”¹è¿›æŠ€æœ¯
            # 1. åå·®æ ¡æ­£
            corrected_output = self.apply_bias_correction(output)
            
            # 2. æ¸©åº¦ç¼©æ”¾
            scaled_output = self.apply_temperature_scaling(corrected_output)
            
            # 3. è®¡ç®—æ¦‚ç‡
            probabilities = F.softmax(scaled_output, dim=-1)
            predicted_class = torch.argmax(probabilities, dim=-1).item()
            confidence = probabilities[0][predicted_class].item()
            
            # 4. ç½®ä¿¡åº¦è¿‡æ»¤ï¼šæ™ºèƒ½é¿å…è¿‡åº¦é¢„æµ‹
            if self.enable_confidence_filtering:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„è¿‡åº¦é¢„æµ‹ï¼ˆä»»ä½•å•ä¸€è¡¨æƒ…è¿‡äºä¸»å¯¼ï¼‰
                max_prob = confidence
                second_highest = sorted(probabilities[0], reverse=True)[1].item()
                
                # å¦‚æœæœ€é«˜æ¦‚ç‡ä¸æ˜¯å‹å€’æ€§çš„ï¼Œä¸”æœ‰å…¶ä»–å€™é€‰
                if max_prob < 0.6 and second_highest > 0.2:
                    # é€‰æ‹©æœ€é«˜æ¦‚ç‡çš„è¡¨æƒ…ï¼Œæ— è®ºæ˜¯å¦ä¸ºä¸­æ€§
                    predicted_class = torch.argmax(probabilities, dim=-1).item()
                    confidence = probabilities[0][predicted_class].item()
            
            predicted_label = self.EMOTION_LABELS[predicted_class]
            
            # æ„å»ºç»“æœ
            result = {
                'predicted_class': predicted_class,
                'predicted_label': predicted_label,
                'confidence': confidence,
                'probabilities': {
                    self.EMOTION_LABELS[i]: prob.item() 
                    for i, prob in enumerate(probabilities[0])
                },
                'model_info': {
                    'has_pretrained': config.has_pretrained_model(),
                    'device': str(self.device),
                    'bias_correction_enabled': self.enable_bias_correction,
                    'confidence_filtering_enabled': self.enable_confidence_filtering
                }
            }
            
            # æ·»åŠ æ”¹è¿›ä¿¡æ¯
            if self.enable_bias_correction:
                result['improvement_info'] = {
                    'original_prediction': self.EMOTION_LABELS[original_pred],
                    'original_confidence': original_confidence,
                    'correction_applied': original_pred != predicted_class,
                    'bias_weights_used': self.BIAS_CORRECTION_WEIGHTS,
                    'confidence_filtering_applied': self.enable_confidence_filtering and confidence < self.confidence_threshold
                }
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.prediction_history.append({
                'timestamp': len(self.prediction_history),
                'predicted_class': predicted_class,
                'confidence': confidence,
                'original_class': original_pred,
                'original_confidence': original_confidence
            })
            
            self.emotion_stats[predicted_label] += 1
            
            return result
            
        except Exception as e:
            self.logger.error(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
            return {
                'predicted_class': 4,
                'predicted_label': self.EMOTION_LABELS[4],
                'confidence': 0.5,
                'probabilities': {label: 1.0/7 for label in self.EMOTION_LABELS.values()},
                'model_info': {
                    'has_pretrained': config.has_pretrained_model(),
                    'device': str(self.device)
                },
                'error': str(e)
            }
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ”¹è¿›æ¨¡å‹ä¿¡æ¯"""
        model_config_info = config.get_model_info()
        
        return {
            'model_name': 'MICACL-FER',
            'version': 'v2.0',
            'num_classes': self.model_args.num_classes,
            'emotion_labels': self.EMOTION_LABELS,
            'device': str(self.device),
            'input_shape': [1, 16, 3, 112, 112],
            'pretrained_info': model_config_info,
            'improvement_features': {
                'bias_correction': {
                    'enabled': self.enable_bias_correction,
                    'weights': self.BIAS_CORRECTION_WEIGHTS
                },
                'temperature_scaling': {
                    'enabled': True,
                    'temperature': self.TEMPERATURE
                },
                'confidence_filtering': {
                    'enabled': self.enable_confidence_filtering,
                    'threshold': self.confidence_threshold
                }
            },
            'statistics': {
                'total_predictions': len(self.prediction_history),
                'emotion_distribution': self.emotion_stats
            }
        }
    
    def configure_parameters(self, 
                          bias_correction_weights: Optional[Dict[int, float]] = None,
                          temperature: Optional[float] = None,
                          confidence_threshold: Optional[float] = None,
                          enable_bias_correction: Optional[bool] = None,
                          enable_confidence_filtering: Optional[bool] = None) -> Dict[str, Any]:
        """
        åŠ¨æ€é…ç½®æ¨¡å‹å‚æ•°
        
        Args:
            bias_correction_weights: åå·®æ ¡æ­£æƒé‡å­—å…¸
            temperature: æ¸©åº¦å‚æ•°
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            enable_bias_correction: æ˜¯å¦å¯ç”¨åå·®æ ¡æ­£
            enable_confidence_filtering: æ˜¯å¦å¯ç”¨ç½®ä¿¡åº¦è¿‡æ»¤
            
        Returns:
            é…ç½®æ›´æ–°ç»“æœ
        """
        updates = {}
        
        if bias_correction_weights is not None:
            self.BIAS_CORRECTION_WEIGHTS.update(bias_correction_weights)
            updates['bias_correction_weights'] = self.BIAS_CORRECTION_WEIGHTS
            
        if temperature is not None:
            self.TEMPERATURE = temperature
            updates['temperature'] = self.TEMPERATURE
            
        if confidence_threshold is not None:
            self.confidence_threshold = confidence_threshold
            updates['confidence_threshold'] = self.confidence_threshold
            
        if enable_bias_correction is not None:
            self.enable_bias_correction = enable_bias_correction
            updates['enable_bias_correction'] = self.enable_bias_correction
            
        if enable_confidence_filtering is not None:
            self.enable_confidence_filtering = enable_confidence_filtering
            updates['enable_confidence_filtering'] = self.enable_confidence_filtering
            
        self.logger.info(f"å‚æ•°é…ç½®å·²æ›´æ–°: {updates}")
        
        return {
            'status': 'success',
            'message': 'å‚æ•°é…ç½®æ›´æ–°æˆåŠŸ',
            'updates': updates,
            'current_config': {
                'bias_correction_weights': self.BIAS_CORRECTION_WEIGHTS,
                'temperature': self.TEMPERATURE,
                'confidence_threshold': self.confidence_threshold,
                'enable_bias_correction': self.enable_bias_correction,
                'enable_confidence_filtering': self.enable_confidence_filtering
            }
        }
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.prediction_history = []
        self.emotion_stats = {emotion: 0 for emotion in self.EMOTION_LABELS.values()}
        self.logger.info("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
        
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        total_predictions = len(self.prediction_history)
        
        if total_predictions == 0:
            return {
                'total_predictions': 0,
                'emotion_distribution': {},
                'average_confidence': 0,
                'correction_rate': 0,
                'message': 'æš‚æ— é¢„æµ‹æ•°æ®'
            }
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_confidence = sum(p['confidence'] for p in self.prediction_history) / total_predictions
        
        # è®¡ç®—æ ¡æ­£ç‡
        corrections = sum(1 for p in self.prediction_history if p['predicted_class'] != p['original_class'])
        correction_rate = corrections / total_predictions
        
        # æ„¤æ€’å’Œææƒ§çš„æ¯”ä¾‹
        anger_fear_count = self.emotion_stats.get('æ„¤æ€’', 0) + self.emotion_stats.get('ææƒ§', 0)
        anger_fear_ratio = anger_fear_count / total_predictions
        
        return {
            'total_predictions': total_predictions,
            'emotion_distribution': self.emotion_stats,
            'average_confidence': avg_confidence,
            'correction_rate': correction_rate,
            'anger_fear_ratio': anger_fear_ratio,
            'recent_predictions': self.prediction_history[-10:] if len(self.prediction_history) > 10 else self.prediction_history
        }
 